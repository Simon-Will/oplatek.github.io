---
layout: post
title: Lab 2, SDS 2016
author: Ondrej Platek
tags: Mff, School, Labs, SDS, dialog systems 
---

## Content

- SLU motivation
- Logistic regression and bag of words
- Using dev set for selecting best model
    - E.g. early stopping for iterative training with stochastic gradient descent (SGD)
- Tensorflow very basics
    - MNIST logistic example
    - Debugging
{% highlight python %}
    json.dump(sess.run(mylist_variable).tolist(), open('mylist.log', 'w'))
{% endhighlight %}
- Logistic regression and cross entropy (if time)


## Homework - Logistic regression

- **Use TensorFlow v0.7.1** Preferably use Python 3.
- Explore [Logistic regression example](https://raw.githubusercontent.com/oplatek/sds-lab/master/slu/code/logistic_regression.py) together with corresponding [data loader](https://raw.githubusercontent.com/oplatek/sds-lab/master/slu/code/input_data.py) for MNIST
- Explore [train, dev, test](https://github.com/oplatek/sds-lab/tree/master/slu/data) data sets for Spoken Language Understanding
    - understand what are the input, output pairs
    - understand that you have two kind of inputs - gold transcriptions and ASR hypothesis
    - implement data loader for bag of words/bigrams features.
- First use bag of words representation as features, later compare it with bag of bigrams
    - Compare using 50%, 70% and 100% top most common words/bigrams
    - Use gold transcriptions as features
- Repeat the same experiment but with ASR transcriptions as features
- Submit your code, together with table plotting results of a logistic regression model for features and data sets
    - datasets - `train, dev, test`
    - features
        - input quality - `asr, golden transcriptions`
        - input form - `words, bigrams`
    - Include commands to **run** your worst and the best model from the table

